# Overview
This project contains the data, scripts, and notebook files needed to recreate the analysis from my capstone project in Political Analytics, ["A Modern Approach to Political Analytics"](https://github.com/brosenzweig27/POAN5990/blob/main/project_overview.pdf). This paper gives a 10,000 foot view of data analytics using neural networks, transformers, and attention; details the journey of building and working with complex neural network models; and explores one use case for training a customizable model to predict voter turnout from varied data sources including the voter file.

While this paper suggests optimistic predictive results from my custom model's analysis, this project serves primarily as an exploration of creative and useful applications of the rapidly developing technologies from the field of machine learning. As such, I caution against drawing strong conclusions from this model's preliminary performance. This project contains many novel elements - from data manipulation, to model design - and aims to inspire future work at the intersection of political science, data science, and computer science. Please see project_overview.pdf (linked above) for more details!

# Where to Start
If you would like to explore all of the code and data manipulation that went into this project, I recommend exploring the notebooks [usage_example.ipynb](https://github.com/brosenzweig27/POAN5990/blob/main/usage_example.ipynb) and [cleaning/clean_jacobson.ipynb](https://github.com/brosenzweig27/POAN5990/blob/main/cleaning/clean_jacobson.ipynb), respectively.

1. **usage_example.ipynb**: This notebook assumes that we have cleaned input data (consisting of individual level voter information from historical election cycles) and corresponding output data (whether they voted in those elections). It goes through each of the critical preparatory steps for training the model, including setting the model's "vocabulary," subsetting data for training and testing, getting input encodings, and creating a model instance. We can then train a small model (with default parameters sufficient to be run locally on basically any laptop) and evaluate its performance. I recommend going down the rabbit hole of each function being imported from the scripts/ folder in order to best understand what's going on under the hood - there's a lot to dig into!
2. **clean_jacobson.ipynb**: This notebook details the convoluted data cleaning and manipulation processes required to train what is functionally a modified language model on messy and continuous quantitative data. While there are many (many) largely arbitrary decisions that get made in this process, this type of data manipulation is not particularly unique, and the notebook *should* be self-explanatory. Good luck!
