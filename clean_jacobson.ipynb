{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pyreadr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Jacobson Data\n",
    "\n",
    "- Import Jacobson data from 1946 onwards and convert to workable csv file.\n",
    "- Print the first five rows for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year   stcd  inc  pwin           dv          dvp   fr  po1  po2  redist  \\\n",
      "0  1946.0  101.0  1.0   1.0 -999999999.0 -999999999.0  0.0  5.0  2.0     0.0   \n",
      "1  1946.0  102.0  1.0   1.0 -999999999.0 -999999999.0  0.0  5.0  2.0     0.0   \n",
      "2  1946.0  103.0  1.0   1.0 -999999999.0 -999999999.0  0.0  5.0  2.0     0.0   \n",
      "3  1946.0  104.0  1.0   1.0         88.1         84.5  0.0  0.0  0.0     0.0   \n",
      "4  1946.0  105.0  1.0   1.0 -999999999.0 -999999999.0  1.0  5.0  2.0     0.0   \n",
      "\n",
      "          dexp         rexp        dpres  \n",
      "0 -999999999.0 -999999999.0 -999999999.0  \n",
      "1 -999999999.0 -999999999.0 -999999999.0  \n",
      "2 -999999999.0 -999999999.0 -999999999.0  \n",
      "3 -999999999.0 -999999999.0 -999999999.0  \n",
      "4 -999999999.0 -999999999.0 -999999999.0  \n"
     ]
    }
   ],
   "source": [
    "result = pyreadr.read_r('house_election_data_46_22.rds')\n",
    "df = result[None]\n",
    "\n",
    "print(df.head())\n",
    "df.to_csv('all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data Types\n",
    "- All non-voteshare columns are either factor variables or campaign spending and can be converted to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  stcd  inc  pwin           dv          dvp  fr  po1  po2  redist  \\\n",
      "0  1946   101    1     1 -999999999.0 -999999999.0   0    5    2       0   \n",
      "1  1946   102    1     1 -999999999.0 -999999999.0   0    5    2       0   \n",
      "2  1946   103    1     1 -999999999.0 -999999999.0   0    5    2       0   \n",
      "3  1946   104    1     1         88.1         84.5   0    0    0       0   \n",
      "4  1946   105    1     1 -999999999.0 -999999999.0   1    5    2       0   \n",
      "\n",
      "        dexp       rexp        dpres  \n",
      "0 -999999999 -999999999 -999999999.0  \n",
      "1 -999999999 -999999999 -999999999.0  \n",
      "2 -999999999 -999999999 -999999999.0  \n",
      "3 -999999999 -999999999 -999999999.0  \n",
      "4 -999999999 -999999999 -999999999.0  \n"
     ]
    }
   ],
   "source": [
    "# Convert all columns to integers except for the exclude_columns\n",
    "\n",
    "exclude_columns = [\"dv\", \"dvp\", \"dpres\"]\n",
    "\n",
    "for column in df.columns:\n",
    "    if column not in exclude_columns:\n",
    "        df[column] = df[column].astype(float).fillna(0).astype(int)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in NaN Values\n",
    "- Negative entries in Jacobson are placeholders for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  stcd  inc  pwin    dv   dvp  fr  po1  po2  redist  dexp  rexp  dpres\n",
      "0  1946   101    1   1.0   NaN   NaN   0  5.0  2.0       0   NaN   NaN    NaN\n",
      "1  1946   102    1   1.0   NaN   NaN   0  5.0  2.0       0   NaN   NaN    NaN\n",
      "2  1946   103    1   1.0   NaN   NaN   0  5.0  2.0       0   NaN   NaN    NaN\n",
      "3  1946   104    1   1.0  88.1  84.5   0  0.0  0.0       0   NaN   NaN    NaN\n",
      "4  1946   105    1   1.0   NaN   NaN   1  5.0  2.0       0   NaN   NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "# Turn negative values into NaNs\n",
    "\n",
    "df = df.mask(df < 0, np.nan)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split \"stcd\" into \"state\" and \"dist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split \"stcd\" into state and district\n",
    "def split_stcd(stcd):\n",
    "    stcd_str = str(stcd)\n",
    "    if len(stcd_str) == 3:\n",
    "        state = int(stcd_str[0])\n",
    "        dist = int(stcd_str[1:])\n",
    "    elif len(stcd_str) == 4:\n",
    "        state = int(stcd_str[:2])\n",
    "        dist = int(stcd_str[2:])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid length of stcd\")\n",
    "    return state, dist\n",
    "\n",
    "# Apply the function to split the stcd column\n",
    "df[['state', 'dist']] = df['stcd'].apply(split_stcd).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Categorical Factor Mappings\n",
    "- Continuous values must be converted to factors, and so must be binned reasonably\n",
    "- map_exp creates expenditure categories ranging from $\\le \\$50,000$ to $> \\$25,000,000$.\n",
    "- map_voteshare creates voteshare categories ranging from $\\le 10\\%$ to $>90\\%$.\n",
    "- Both categories become more granular (smaller bin sizes) around the mode of each category.\n",
    "- Apply these mappings to all applicable columns and delete remaining extraneous columns.\n",
    "\n",
    "## Additionally Create Broader Categories\n",
    "- Since multicolinearity is not a concern, adding less granular categories will not detract from model accuracy\n",
    "- We can theoretically consider as many different sized bins as we like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  inc  pwin  fr  po1  po2  redist  state  dist  dexp_cat_gran  \\\n",
      "0  1946    1   1.0   0  5.0  2.0       0      1     1            NaN   \n",
      "1  1946    1   1.0   0  5.0  2.0       0      1     2            NaN   \n",
      "2  1946    1   1.0   0  5.0  2.0       0      1     3            NaN   \n",
      "3  1946    1   1.0   0  0.0  0.0       0      1     4            NaN   \n",
      "4  1946    1   1.0   1  5.0  2.0       0      1     5            NaN   \n",
      "\n",
      "   rexp_cat_gran  dexp_cat  rexp_cat  dpres_cat  dvp_cat  dv_cat  \n",
      "0            NaN       NaN       NaN        NaN      NaN     NaN  \n",
      "1            NaN       NaN       NaN        NaN      NaN     NaN  \n",
      "2            NaN       NaN       NaN        NaN      NaN     NaN  \n",
      "3            NaN       NaN       NaN        NaN     31.0    32.0  \n",
      "4            NaN       NaN       NaN        NaN      NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "# Turn real variables into ranges using maps\n",
    "def map_exp_granular(value):\n",
    "    if value <= 50000:\n",
    "        return 0\n",
    "    elif value <= 100000:\n",
    "        return 1\n",
    "    elif value <= 200000:\n",
    "        return 2\n",
    "    elif value <= 300000:\n",
    "        return 3\n",
    "    elif value <= 400000:\n",
    "        return 4\n",
    "    elif value <= 500000:\n",
    "        return 5\n",
    "    elif value <= 600000:\n",
    "        return 6\n",
    "    elif value <= 700000:\n",
    "        return 7\n",
    "    elif value <= 800000:\n",
    "        return 8\n",
    "    elif value <= 900000:\n",
    "        return 9\n",
    "    elif value <= 1000000:\n",
    "        return 10\n",
    "    elif value <= 1250000:\n",
    "        return 11\n",
    "    elif value <= 1500000:\n",
    "        return 12\n",
    "    elif value <= 1750000:\n",
    "        return 13\n",
    "    elif value <= 2000000:\n",
    "        return 14\n",
    "    elif value <= 2500000:\n",
    "        return 15\n",
    "    elif value <= 3000000:\n",
    "        return 16\n",
    "    elif value <= 4000000:\n",
    "        return 17\n",
    "    elif value <= 5000000:\n",
    "        return 18\n",
    "    elif value <= 6000000:\n",
    "        return 19\n",
    "    elif value <= 7500000:\n",
    "        return 20\n",
    "    elif value <= 9000000:\n",
    "        return 21\n",
    "    elif value <= 12000000:\n",
    "        return 22\n",
    "    elif value <= 15000000:\n",
    "        return 23\n",
    "    elif value <= 17500000:\n",
    "        return 24\n",
    "    elif value <= 20000000:\n",
    "        return 25\n",
    "    elif value <= 22500000:\n",
    "        return 26\n",
    "    elif value <= 25000000:\n",
    "        return 27\n",
    "    else: pass\n",
    "\n",
    "def map_exp(value):\n",
    "    if value <= 100000:\n",
    "        return 0\n",
    "    elif value <= 400000:\n",
    "        return 1\n",
    "    elif value <= 600000:\n",
    "        return 2\n",
    "    elif value <= 900000:\n",
    "        return 3\n",
    "    elif value <= 1250000:\n",
    "        return 4\n",
    "    elif value <= 1500000:\n",
    "        return 5\n",
    "    elif value <= 2000000:\n",
    "        return 6\n",
    "    elif value <= 3000000:\n",
    "        return 7\n",
    "    elif value <= 6000000:\n",
    "        return 8\n",
    "    elif value <= 9000000:\n",
    "        return 9\n",
    "    elif value <= 12000000:\n",
    "        return 10\n",
    "    elif value <= 17500000:\n",
    "        return 11\n",
    "    elif value <= 22500000:\n",
    "        return 12\n",
    "    else: pass\n",
    "\n",
    "df['dexp_cat_gran'] = df['dexp'].apply(map_exp_granular)\n",
    "df['rexp_cat_gran'] = df['rexp'].apply(map_exp_granular)\n",
    "\n",
    "df['dexp_cat'] = df['dexp'].apply(map_exp)\n",
    "df['rexp_cat'] = df['rexp'].apply(map_exp)\n",
    "\n",
    "def map_voteshare(value):\n",
    "    if value <= 10:\n",
    "        return 0\n",
    "    elif value <= 15:\n",
    "        return 1\n",
    "    elif value <= 20:\n",
    "        return 2\n",
    "    elif value <= 25:\n",
    "        return 3\n",
    "    elif value <= 30:\n",
    "        return 4\n",
    "    elif value <= 33:\n",
    "        return 5\n",
    "    elif value <= 36:\n",
    "        return 6\n",
    "    elif value <= 39:\n",
    "        return 7\n",
    "    elif value <= 41:\n",
    "        return 8\n",
    "    elif value <= 43:\n",
    "        return 9\n",
    "    elif value <= 45:\n",
    "        return 10\n",
    "    elif value <= 46:\n",
    "        return 11\n",
    "    elif value <= 47:\n",
    "        return 12\n",
    "    elif value <= 48:\n",
    "        return 13\n",
    "    elif value <= 49:\n",
    "        return 14\n",
    "    elif value <= 49.5:\n",
    "        return 15\n",
    "    elif value <= 50:\n",
    "        return 16\n",
    "    elif value <= 50.5:\n",
    "        return 17\n",
    "    elif value <= 51:\n",
    "        return 18\n",
    "    elif value <= 52:\n",
    "        return 19\n",
    "    elif value <= 53:\n",
    "        return 20\n",
    "    elif value <= 54:\n",
    "        return 21\n",
    "    elif value <= 55:\n",
    "        return 22\n",
    "    elif value <= 57:\n",
    "        return 23\n",
    "    elif value <= 59:\n",
    "        return 24\n",
    "    elif value <= 61:\n",
    "        return 25\n",
    "    elif value <= 64:\n",
    "        return 26\n",
    "    elif value <= 67:\n",
    "        return 27\n",
    "    elif value <= 70:\n",
    "        return 28\n",
    "    elif value <= 75:\n",
    "        return 29\n",
    "    elif value <= 80:\n",
    "        return 30\n",
    "    elif value <= 85:\n",
    "        return 31\n",
    "    elif value <= 90:\n",
    "        return 32\n",
    "    elif value <= 100:\n",
    "        return 33\n",
    "    else: pass\n",
    "\n",
    "df['dpres_cat'] = df['dpres'].apply(map_voteshare)\n",
    "df['dvp_cat'] = df['dvp'].apply(map_voteshare)\n",
    "df['dv_cat'] = df['dv'].apply(map_voteshare)\n",
    "\n",
    "# Delete original columns\n",
    "del df['dvp'], df['dpres'], df['dexp'], df['rexp'], df['stcd'], df['dv']\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Seperate File for Output Variables\n",
    "- In this case, 'pwin' and 'dv_cat.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  inc  fr  po1  po2  redist  state  dist  dexp_cat_gran  rexp_cat_gran  \\\n",
      "0  1946    1   0  5.0  2.0       0      1     1            NaN            NaN   \n",
      "1  1946    1   0  5.0  2.0       0      1     2            NaN            NaN   \n",
      "2  1946    1   0  5.0  2.0       0      1     3            NaN            NaN   \n",
      "3  1946    1   0  0.0  0.0       0      1     4            NaN            NaN   \n",
      "4  1946    1   1  5.0  2.0       0      1     5            NaN            NaN   \n",
      "\n",
      "   dexp_cat  rexp_cat  dpres_cat  dvp_cat  \n",
      "0       NaN       NaN        NaN      NaN  \n",
      "1       NaN       NaN        NaN      NaN  \n",
      "2       NaN       NaN        NaN      NaN  \n",
      "3       NaN       NaN        NaN     31.0  \n",
      "4       NaN       NaN        NaN      NaN  \n",
      "   pwin  dv_cat\n",
      "0     1     NaN\n",
      "1     1     NaN\n",
      "2     1     NaN\n",
      "3     1    32.0\n",
      "4     1     NaN\n"
     ]
    }
   ],
   "source": [
    "# Filter and create target df\n",
    "filt = df.drop(columns = [\"pwin\", \"dv_cat\"])\n",
    "out = df[[\"pwin\", \"dv_cat\"]]\n",
    "\n",
    "out.loc[:, 'pwin'] = out['pwin'].astype('Int64')\n",
    "\n",
    "print(filt.head())\n",
    "print(out.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to do With Missing Data?\n",
    "1. **Nothing**: Machine learning algorithm in pred2022.ipynb is capable of only training givin only the available data\n",
    "2. **Missing as a Vocab Item**: Allow the model to treat missingness as a datapoint, by storing any NaN as a vocabulary item\n",
    "3. **Impute with Mean**: Impute any missing item with the average value of the column or year\n",
    "4. **Impute with Mode**: Impute any missing item with the most common value of the column or year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  inc  fr  po1  po2  redist  state  dist  dexp_cat_gran  rexp_cat_gran  \\\n",
      "0  1946    1   0  5.0  2.0       0      1     1         2342.0         2342.0   \n",
      "1  1946    1   0  5.0  2.0       0      1     2         2342.0         2342.0   \n",
      "2  1946    1   0  5.0  2.0       0      1     3         2342.0         2342.0   \n",
      "3  1946    1   0  0.0  0.0       0      1     4         2342.0         2342.0   \n",
      "4  1946    1   1  5.0  2.0       0      1     5         2342.0         2342.0   \n",
      "\n",
      "   dexp_cat  rexp_cat  dpres_cat  dvp_cat  \n",
      "0    2342.0    2342.0     2342.0   2342.0  \n",
      "1    2342.0    2342.0     2342.0   2342.0  \n",
      "2    2342.0    2342.0     2342.0   2342.0  \n",
      "3    2342.0    2342.0     2342.0     31.0  \n",
      "4    2342.0    2342.0     2342.0   2342.0  \n",
      "   pwin  dv_cat\n",
      "0     1     NaN\n",
      "1     1     NaN\n",
      "2     1     NaN\n",
      "3     1    32.0\n",
      "4     1     NaN\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# Strategy 2: This code converts all missing data to a unique value to be turned into a vocab item\n",
    "\n",
    "## The value (2342 here) just needs to be unique to that column and carries no real value\n",
    "\n",
    "### We cannot do this to missing outcomes, we do not want the model predicting NaN results\n",
    "###################################################################\n",
    "\n",
    "filt_nona = filt.fillna(2342)\n",
    "print(filt_nona.head())\n",
    "print(out.head())\n",
    "\n",
    "# I want to export this as my data, so for now I will call this 'filt' for the code below\n",
    "filt = filt_nona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housekeeping\n",
    "- Check how many NaNs are in the dataset. If we have executed cell 28, this will be 0 since NaNs have been treated as arbitrary numbers.\n",
    "- Make sure all values are integers if they are supposed to be.\n",
    "- Print the number of unique entries of each column to get a sense of vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of values for feature year:39\n",
      "The number of values for feature inc:12\n",
      "The number of values for feature fr :6 -- [0 1 2 3 8 9]\n",
      "The number of values for feature po1:10\n",
      "The number of values for feature po2:11\n",
      "The number of values for feature redist :4 -- [0 1 4 6]\n",
      "The number of values for feature state:50\n",
      "The number of values for feature dist:53\n",
      "The number of values for feature dexp_cat_gran:28\n",
      "The number of values for feature rexp_cat_gran:28\n",
      "The number of values for feature dexp_cat:14\n",
      "The number of values for feature rexp_cat:14\n",
      "The number of values for feature dpres_cat:35\n",
      "The number of values for feature dvp_cat:35\n"
     ]
    }
   ],
   "source": [
    "filt.isnull().sum()\n",
    "out.isnull().sum()\n",
    "\n",
    "# Turn columns of filt into integers if they are float\n",
    "for col in filt.columns:\n",
    "    filt.loc[:, col] = filt[col].astype('Int64')\n",
    "\n",
    "for col in out.columns:\n",
    "    out.loc[:, col] = out[col].astype('Int64')\n",
    "\n",
    "# Print the number of unique items in each column to get a sense of \"vocabulary\" size\n",
    "for column in filt:\n",
    "    try: \n",
    "        unique_vals = np.unique(df[column])\n",
    "    except:\n",
    "        unique_vals = df[column].unique()\n",
    "\n",
    "    nr_vals = len(unique_vals)\n",
    "    if nr_vals < 10:\n",
    "        print('The number of values for feature {} :{} -- {}'.format(column, nr_vals, unique_vals))\n",
    "    else:\n",
    "        print('The number of values for feature {}:{}'.format(column, nr_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Data\n",
    "- If desired, examine relationships between any two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.pairplot(df[['inc', 'dvp_cat', 'po1', 'rexp_cat', 'dexp_cat', 'state', 'dist', 'pwin', 'dpres_cat']], hue='pwin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Column IDs\n",
    "- A number of columns contain the same items, but the neural network must still be able to distinguish between them. Since column order may be shuffled in the network, add column identification letters to each non-NaN element of the dataset.\n",
    "- This creates a full vocabulary of inputs and outputs representing all entries of each column that can be utilized by the neural network eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year inc  fr   po1   po2 redist state dist dexp_cat_gran rexp_cat_gran  \\\n",
      "0  a1946  b1  c0  d5.0  e2.0     f0    g1   h1       i2342.0       j2342.0   \n",
      "1  a1946  b1  c0  d5.0  e2.0     f0    g1   h2       i2342.0       j2342.0   \n",
      "2  a1946  b1  c0  d5.0  e2.0     f0    g1   h3       i2342.0       j2342.0   \n",
      "3  a1946  b1  c0  d0.0  e0.0     f0    g1   h4       i2342.0       j2342.0   \n",
      "4  a1946  b1  c1  d5.0  e2.0     f0    g1   h5       i2342.0       j2342.0   \n",
      "\n",
      "  dexp_cat rexp_cat dpres_cat  dvp_cat  \n",
      "0  k2342.0  l2342.0   m2342.0  n2342.0  \n",
      "1  k2342.0  l2342.0   m2342.0  n2342.0  \n",
      "2  k2342.0  l2342.0   m2342.0  n2342.0  \n",
      "3  k2342.0  l2342.0   m2342.0    n31.0  \n",
      "4  k2342.0  l2342.0   m2342.0  n2342.0  \n",
      "<bound method NDFrame.head of       pwin dv_cat\n",
      "0       a1   <NA>\n",
      "1       a1   <NA>\n",
      "2       a1   <NA>\n",
      "3       a1    b32\n",
      "4       a1   <NA>\n",
      "...    ...    ...\n",
      "16963   a0     b6\n",
      "16964   a0   <NA>\n",
      "16965   a0     b7\n",
      "16966   a0   <NA>\n",
      "16967   a0     b4\n",
      "\n",
      "[16968 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Map each column to a letter\n",
    "column_mapping_filt = dict(zip(filt.columns, string.ascii_lowercase))\n",
    "column_mapping_out = dict(zip(out.columns, string.ascii_lowercase))\n",
    "\n",
    "def append_letter(val, col_name, column_mapping):\n",
    "    if pd.notna(val):\n",
    "        return f\"{column_mapping[col_name]}{val}\"\n",
    "    else:\n",
    "        return val  # Return NaN if the value is NaN\n",
    "\n",
    "# Apply the function element-wise to the DataFrame\n",
    "for col in filt.columns:\n",
    "    filt.loc[:, col] = filt[col].apply(lambda x, col_name=col: append_letter(x, col_name, column_mapping_filt))\n",
    "\n",
    "# Apply the function element-wise to outputs using .loc as well\n",
    "for col in out.columns:\n",
    "    out.loc[:, col] = out[col].apply(lambda x, col_name=col: append_letter(x, col_name, column_mapping_out))\n",
    "\n",
    "# Convert all values in the DataFrame to strings\n",
    "filt = filt.astype(str)\n",
    "filt = filt.replace(\"<NA>\", pd.NA)\n",
    "\n",
    "out = out.astype(str)\n",
    "out = out.replace(\"<NA>\", pd.NA)\n",
    "\n",
    "print(filt.head())\n",
    "print(out.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt.to_csv('filtered_data.csv', index=False)\n",
    "out.to_csv('targets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "littleguy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
